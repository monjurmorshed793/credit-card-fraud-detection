{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve,roc_auc_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('/mnt/d/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 284315\n",
      "Class 1: 492\n",
      "Proportion: 577.88 : 1\n",
      "(227845, 30)\n",
      "(56962, 30)\n",
      "Overall Oversampling:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     56868\n",
      "         1.0       0.65      0.84      0.73        94\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.82      0.92      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Before Split: (284807, 31)\n",
      "After Split: (142404, 31)\n",
      "X_Test Ratio: (28481, 30) Y-Ratio (28481,)\n",
      "Class-1 0: 142135\n",
      "Class-1 1: 269\n",
      "Proportion-1: 528.0 : 1\n",
      "(227426, 30)\n",
      "(227426, 30)\n",
      "Random Oversampling:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     28422\n",
      "         1.0       0.70      0.90      0.79        59\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.85      0.95      0.89     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Test Result:1 ['   macro avg', ' 0.85', '0.95', '0.89     28481']\n",
      "After Split -2: (142403, 31)\n",
      "X_Test Ratio: (28481, 30) Y-Ratio (28481,)\n",
      "Class-2 0: 142180\n",
      "Class-2 1: 223\n",
      "Proportion-2: 638.0 : 1\n",
      "(227498, 30)\n",
      "(227498, 30)\n",
      "Random UnderSampling:               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     28431\n",
      "         1.0       0.69      0.84      0.76        50\n",
      "\n",
      "    accuracy                           1.00     28481\n",
      "   macro avg       0.84      0.92      0.88     28481\n",
      "weighted avg       1.00      1.00      1.00     28481\n",
      "\n",
      "Accuracy Split-1 ROC: 94.87%\n",
      "Accuracy Split-2 ROC: 91.97%\n",
      "Whole Precision:  0.82 Recall: 0.92 F1-Measure: 0.87     56962\n",
      "Split-1 Precision:  0.85 Recall: 0.95 F1-Measure: 0.89     28481\n",
      "Split-2 Precision:  0.84 Recall: 0.92 F1-Measure: 0.88     28481\n",
      "Test-22 0.85 Test21 0.84\n",
      "=============================================================\n",
      "\n",
      "\n",
      "== Random OverSampling (ROS) and Our model Result Values ==\n",
      "ROS ROC-AUC: 91.98%\n",
      "Accuracy Avg ROC: 93.42%\n",
      "ROS Precision:  0.82 ROS Recall: 0.92 ROS F1-Measure: 0.87     56962\n",
      "Avg Precision: 0.84 Avg Recall: 0.94 Avg F-Measure: 0.89\n"
     ]
    }
   ],
   "source": [
    "### Credit Card Fraud and Non-Fraud ration with graph\n",
    "target_count = df_train['Class'].value_counts()\n",
    "print('Class 0:', target_count[0])\n",
    "print('Class 1:', target_count[1])\n",
    "print('Proportion:', round(target_count[0] / target_count[1], 2), ': 1')\n",
    "\n",
    "#target_count.plot(kind='bar', title='Count (target)');\n",
    "\n",
    "## End of Class ratio\n",
    "\n",
    "# Here we use Robust Scaler technique for feature scalling\n",
    "# Scale \"Time\" and \"Amount\"\n",
    "\n",
    "\n",
    "\n",
    "df_train['scaled_amount'] = RobustScaler().fit_transform(df_train['Amount'].values.reshape(-1,1))\n",
    "df_train['scaled_time'] = RobustScaler().fit_transform(df_train['Time'].values.reshape(-1,1))\n",
    "\n",
    "# Make a new dataset named \"df_scaled\" dropping out original \"Time\" and \"Amount\"\n",
    "df_scaled = df_train.drop(['Time','Amount'],axis = 1,inplace=False)\n",
    "df_scaled.head()\n",
    "\n",
    "# Define the prep_data function to extrac features \n",
    "def prep_data(df):\n",
    "    X = df.drop(['Class'],axis=1, inplace=False)  \n",
    "    X = np.array(X).astype(np.float)\n",
    "    y = df[['Class']]  \n",
    "    y = np.array(y).astype(np.float)\n",
    "    return X,y\n",
    "\n",
    "# Create X and y from the prep_data function \n",
    "X, y = prep_data(df_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "print(X_train.shape)\n",
    "\n",
    "# ****** LogisticRegression Accuration test\n",
    "##model = LogisticRegression()\n",
    "##model.fit(X_train, y_train)\n",
    "##y_pred = model.predict(X_test)\n",
    "\n",
    "##accuracy = accuracy_score(y_test, y_pred)\n",
    "##print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "# End of accuracy test\n",
    "\n",
    "\n",
    "# Random UnderSampling\n",
    "undersam = RandomOverSampler()\n",
    "# resample the training data\n",
    "X_undersam, y_undersam = undersam.fit_sample(X_train,y_train)\n",
    "\n",
    "#After resampling again accuracy count\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_undersam, y_undersam)\n",
    "y_pred_under = model.predict(X_test)\n",
    "print(X_test.shape)\n",
    "\n",
    "print('Overall Oversampling:',classification_report(y_test, model.predict(X_test)))\n",
    "\n",
    "#************ Average Result (Precision,Recall, F1-Measure) ***************#\n",
    "def classifaction_report_rst(report):\n",
    "    i=0\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-2]: \n",
    "        i=i+1\n",
    "        if i==5:\n",
    "            row_data = line.split('      ')\n",
    "            return row_data\n",
    "        \n",
    "#************** End of Average Result ******************#\n",
    "\n",
    "report0 = classification_report(y_test, model.predict(X_test))\n",
    "avgrst0 =  classifaction_report_rst(report0)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_under)\n",
    "\n",
    "#print(\"============ Decision Tree Classifier ================%\")\n",
    "#print(\"Accuracy After RandomUnderSampler: %.2f%%\" % (accuracy * 100.0))\n",
    "roc_auc = roc_auc_score(y_test, y_pred_under)\n",
    "\n",
    "#precision, recall, thresholds = precision_recall_curve(y_test, y_pred_under)\n",
    "pre_scor= precision_score(y_test, y_pred_under)\n",
    "re_scor = recall_score(y_test, y_pred_under)\n",
    "f1_scor = f1_score(y_test, y_pred_under)\n",
    "##print(\"\\n ROC AUC Score:  %.2f%%\" % (roc_auc * 100.0))\n",
    "#print(\"Precision Score:  %.2f%%\" % (pre_scor * 100.0))\n",
    "#print(\"Recall Score:  %.2f%%\" % (re_scor * 100.0))\n",
    "#print('F1-Measure: %.2f%%' % (f1_scor * 100.0))\n",
    "\n",
    "############################################\n",
    "# Class count\n",
    "# Define the prep_data function to extrac features \n",
    "def prep_data1(df):\n",
    "    X1 = df[:, :-1]\n",
    "    y1 = df[:, -1] \n",
    "    return X1,y1\n",
    "\n",
    "# Create X and y from the prep_data function \n",
    "X, y = prep_data(df_scaled)\n",
    "y= y.astype(np.int64)\n",
    "#print(Counter(y))\n",
    "\n",
    "df_ar_x = pd.DataFrame(X)\n",
    "df_ar_y = pd.DataFrame(y)\n",
    "df_xy=pd.concat([df_ar_x,df_ar_y],axis=1)\n",
    "print('Before Split:',df_xy.shape)\n",
    "\n",
    "\n",
    "#var i=0\n",
    "i=0\n",
    "two_split = np.array_split(df_xy, 2)\n",
    "\n",
    "#****************** Slit-1 ****************#\n",
    "data1 = np.array(two_split[0]).astype(np.float)\n",
    "#data2 = np.array(two_split[1]).astype(np.float)\n",
    "print('After Split:',data1.shape)\n",
    "X1 , y1 = prep_data1(data1)\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=10)\n",
    "print('X_Test Ratio:',X_test1.shape, 'Y-Ratio', y_test1.shape)\n",
    "#----------\n",
    "df1 = pd.DataFrame(y1, columns = ['Class'])\n",
    "target_count1 = df1['Class'].value_counts()\n",
    "print('Class-1 0:', target_count1[0])\n",
    "print('Class-1 1:', target_count1[1])\n",
    "print('Proportion-1:', round(target_count1[0] / target_count1[1], 0), ': 1')\n",
    "#-------------\n",
    "# Random UnderSampling\n",
    "#RandomUnderSampler\n",
    "#DecisionTreeClassifier\n",
    "over1 = RandomOverSampler()\n",
    "# resample the training data\n",
    "X_over1, y_over1 = over1.fit_sample(X_train1,y_train1)\n",
    "print(X_over1.shape)\n",
    "print(X_over1.shape)\n",
    "\n",
    "#----------\n",
    "#df2 = pd.DataFrame(y_over1, columns = ['Class'])\n",
    "#target_count2 = df2['Class'].value_counts()\n",
    "#print('Class-2 0:', target_count2[0])\n",
    "#print('Class-2 1:', target_count2[1])\n",
    "#print('After OverSampling Proportion:', round(target_count2[0] / target_count2[1], 0), ': 1')\n",
    "\n",
    "#-------------\n",
    "#After resampling again accuracy count\n",
    "model1 = KNeighborsClassifier()\n",
    "model1.fit(X_over1, y_over1)\n",
    "y_pred_over1 = model1.predict(X_test1)\n",
    "\n",
    "\n",
    "print('Random Oversampling:',classification_report(y_test1, model1.predict(X_test1)))\n",
    "\n",
    "roc_auc1 = roc_auc_score(y_test1, model1.predict(X_test1))\n",
    "\n",
    "\n",
    "report1 = classification_report(y_test1, model1.predict(X_test1))\n",
    "avgrst1 =  classifaction_report_rst(report1)\n",
    "print('Test Result:1',avgrst1)\n",
    "\n",
    "#****************** Slit-2 ****************#\n",
    "#data1 = np.array(two_split[0]).astype(np.float)\n",
    "data2 = np.array(two_split[1]).astype(np.float)\n",
    "print('After Split -2:',data2.shape)\n",
    "X2 , y2 = prep_data1(data2)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=10)\n",
    "print('X_Test Ratio:',X_test2.shape, 'Y-Ratio', y_test2.shape)\n",
    "#----------\n",
    "df2 = pd.DataFrame(y2, columns = ['Class'])\n",
    "target_count2 = df2['Class'].value_counts()\n",
    "print('Class-2 0:', target_count2[0])\n",
    "print('Class-2 1:', target_count2[1])\n",
    "print('Proportion-2:', round(target_count2[0] / target_count2[1], 0), ': 1')\n",
    "#-------------\n",
    "# Random UnderSampling\n",
    "#RandomUnderSampler\n",
    "#DecisionTreeClassifier\n",
    "over2 = RandomOverSampler()\n",
    "# resample the training data\n",
    "X_over2, y_over2 = over2.fit_sample(X_train2,y_train2)\n",
    "print(X_over2.shape)\n",
    "print(X_over2.shape)\n",
    "\n",
    "#----------\n",
    "#df2 = pd.DataFrame(y_over1, columns = ['Class'])\n",
    "#target_count2 = df2['Class'].value_counts()\n",
    "#print('Class-2 0:', target_count2[0])\n",
    "#print('Class-2 1:', target_count2[1])\n",
    "#print('After OverSampling Proportion:', round(target_count2[0] / target_count2[1], 0), ': 1')\n",
    "\n",
    "#-------------\n",
    "#After resampling again accuracy count\n",
    "model2 = KNeighborsClassifier()\n",
    "model2.fit(X_over2, y_over2)\n",
    "y_pred_over2 = model2.predict(X_test2)\n",
    "print('Random UnderSampling:',classification_report(y_test2, model2.predict(X_test2)))\n",
    "roc_auc2 = roc_auc_score(y_test2, model2.predict(X_test2))\n",
    "\n",
    "\n",
    "\n",
    "report = classification_report(y_test2, model2.predict(X_test2))\n",
    "#p2,r2,f12 = classification_report_rst(report)\n",
    "avgrst2 =  classifaction_report_rst(report)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy Split-1 ROC: %.2f%%\" % (roc_auc1 * 100.0))\n",
    "print(\"Accuracy Split-2 ROC: %.2f%%\" % (roc_auc2 * 100.0))\n",
    "\n",
    "\n",
    "f11measure = avgrst1[3][0:4]\n",
    "f12measure = avgrst2[3][0:4]\n",
    "\n",
    "print('Whole Precision:',avgrst0[1],'Recall:',avgrst0[2],'F1-Measure:',avgrst0[3])\n",
    "print('Split-1 Precision:',avgrst1[1],'Recall:',avgrst1[2],'F1-Measure:',avgrst1[3])\n",
    "print('Split-2 Precision:',avgrst2[1],'Recall:',avgrst2[2],'F1-Measure:',avgrst2[3])\n",
    "p1 = round(float(avgrst1[1]),2)\n",
    "p2 = round(float(avgrst2[1]),2)\n",
    "print('Test-22',p1,'Test21',p2)\n",
    "r1 = round(float(avgrst1[2]),2)\n",
    "r2 = round(float(avgrst2[2]),2)\n",
    "f1 = round(float(f11measure),2)\n",
    "f2 = round(float(f12measure),2)\n",
    "\n",
    "print('=============================================================\\n\\n')\n",
    "print(\"== Random OverSampling (ROS) and Our model Result Values ==\")\n",
    "\n",
    "print(\"ROS ROC-AUC: %.2f%%\" % (roc_auc * 100.0))\n",
    "print(\"Accuracy Avg ROC: %.2f%%\" % ((roc_auc1+roc_auc2)/2 * 100.0))\n",
    "\n",
    "print('ROS Precision:',avgrst0[1],'ROS Recall:',avgrst0[2],'ROS F1-Measure:',avgrst0[3])\n",
    "print('Avg Precision:',round(((p1+p2)/2),2) , 'Avg Recall:',round(((r1+r2)/2),2) ,'Avg F-Measure:', round(((f1+f2)/2),2) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
